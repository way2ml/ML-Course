{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度神经网络入门 --实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 神经元\n",
    "![](https://cdn.jsdelivr.net/gh/HuangJiaLian/DataBase0@master/uPic/2021_11_07_18_2021_11_01_11_3CIDZe.jpg)\n",
    "\n",
    "面向对象的思维\n",
    "\n",
    "单个神经元的\n",
    "- 属性有哪些?\n",
    "- 功能有什么?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 先加权求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = 0.1 \n",
    "x2 = 0.5\n",
    "x3 = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 也可以这样， 一次性赋值\n",
    "w1, w2, w3 = 2, 1, 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = w1 * x1 + w2*x2 + w3*x3 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第三方库的导入\n",
    "# 简化一点\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://numpy.org/doc/stable/_static/numpylogo.svg)](https://numpy.org/doc/stable/user/whatisnumpy.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.5 0.8]\n",
      "[2.  1.  0.5]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([x1, x2, x3])\n",
    "w = np.array([w1, w2, w3])\n",
    "print(x)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6\n"
     ]
    }
   ],
   "source": [
    "output = np.dot(x, w) + b\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 说明文档\n",
    "`numpy.dot`的[参考说明](https://numpy.org/doc/stable/reference/generated/numpy.dot.html)\n",
    "\n",
    "- 分一维和二维\n",
    "- 不用记忆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 激活函数\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1+e^{-z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数定义\n",
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid 激活函数\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列表: 画出激活函数的图像\n",
    "z_s = [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新建空的列表\n",
    "a_s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取 z_s 里面的每一个数(第1个， 第3个， 最后一个， 倒数第2个， 从第二个开始到最后)\n",
    "z_s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# 循环: 方法1\n",
    "# 取 z_s 里面的每一个数\n",
    "for z in z_s:\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0066928509242848554\n",
      "0.01798620996209156\n",
      "0.04742587317756678\n",
      "0.11920292202211755\n",
      "0.2689414213699951\n",
      "0.5\n",
      "0.7310585786300049\n",
      "0.8807970779778823\n",
      "0.9525741268224334\n",
      "0.9820137900379085\n",
      "0.9933071490757153\n"
     ]
    }
   ],
   "source": [
    "# 循环\n",
    "for z in z_s:\n",
    "    a = sigmoid(z)\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# 循环: 方法2, 用索引号\n",
    "# 取 z_s 里面的每一个数\n",
    "num = len(z_s)\n",
    "for i in range(num):\n",
    "    print(z_s[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in z_s:\n",
    "    a = sigmoid(z)\n",
    "    a_s.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0066928509242848554,\n",
       " 0.01798620996209156,\n",
       " 0.04742587317756678,\n",
       " 0.11920292202211755,\n",
       " 0.2689414213699951,\n",
       " 0.5,\n",
       " 0.7310585786300049,\n",
       " 0.8807970779778823,\n",
       " 0.9525741268224334,\n",
       " 0.9820137900379085,\n",
       " 0.9933071490757153]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作图\n",
    "[<img src='https://matplotlib.org/_static/images/logo2.svg' width='40%'>](https://matplotlib.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(z_s, a_s)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('$\\sigma (z)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简化一点: 不用循环\n",
    "# 利用Numpy这种element-wize的计算特性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_s = np.array([-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_s = sigmoid(z_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00669285 0.01798621 0.04742587 0.11920292 0.26894142 0.5\n",
      " 0.73105858 0.88079708 0.95257413 0.98201379 0.99330715] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(a_s, type(a_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z_s, a_s)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('$\\sigma (z)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 综合一下: 单个神经元的计算\n",
    "output = np.dot(x, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sigmoid(np.dot(x, w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973403006423134\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  面向对象的写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义神经元 类\n",
    "class neuron:\n",
    "    def __init__(self, x, w, b):\n",
    "        self.x = x\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "    \n",
    "    def out(self):\n",
    "        return self.sigmoid(np.dot(self.w, self.x) + self.b)\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = neuron(x=x, w=w, b=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.973403006423134"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1.out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 神经层\n",
    "<img src='https://cdn.jsdelivr.net/gh/HuangJiaLian/DataBase0@master/uPic/2021_11_18_22_nn.png' width='40%'/>\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{l}a_{20} \\\\ a_{21}  \\end{array}\\right]= \n",
    "\\sigma \\left ( \\left[\\begin{array}{llll}\n",
    "w_{00} & w_{01} & w_{02}\\\\ \n",
    "w_{10} & w_{11} & w_{12}\\\\ \n",
    "\\end{array}\\right]\\left[\\begin{array}{l}a_{10} \\\\ a_{11} \\\\ a_{12} \\end{array}\\right]+\\left[\\begin{array}{l}b_{20} \\\\ b_{21} \\end{array}\\right] \\right )\n",
    "$$\n",
    "\n",
    "一层神经元的属性有哪些?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 红色层(第二层)\n",
    "w00, w01, w02 = 1, 2, 3\n",
    "w10, w11, w12 = 2, 2, 2\n",
    "w = np.array([[w00, w01, w02], [w10, w11, w12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [2, 2, 2]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上一层的输出\n",
    "a10, a11, a12 = 1, 1 , 1\n",
    "a1 = np.array([a10, a11, a12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(w,a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = np.dot(w,a1) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 8])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = sigmoid(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99908895, 0.99966465])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(self, x, w, b):\n",
    "        self.x = x \n",
    "        self.w = w \n",
    "        self.b = b\n",
    "    \n",
    "    def out(self):\n",
    "        return self.sigmoid(np.dot(self.w, self.x) + self.b)\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = layer(x=a1, w=w, b=b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99908895, 0.99966465])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    def __init__(self, weights, biases):\n",
    "        self.weights = weights\n",
    "        self.biases = biases\n",
    "    \n",
    "    # 前向传播\n",
    "    def feedforward(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            a = self.sigmoid(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证是否写正确了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  网络结构 sizes = [3, 3, 3]\n",
    "# 输入层\n",
    "x = np.array([1,1,1])\n",
    "a0 = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一层\n",
    "w1 = np.array([[1, 2, 1], [2, 2, 2], [1,1,3]])\n",
    "b1= np.array([1,1,2])\n",
    "# 具体化\n",
    "l_1 = layer(x=a0, w=w1, b=b1)\n",
    "# 第一层输出\n",
    "a1 = l_1.out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二层\n",
    "w2 = np.array([[0.1, 0.2, 1], [2, 0.2, 2], [1,0.1,0.3]])\n",
    "b2= np.array([1,1,2])\n",
    "l_2 = layer(x=a1, w=w2, b=b2)\n",
    "a_2 = l_2.out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90873096, 0.99442909, 0.96748325])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 用Network类去验证\n",
    "weights = [w1, w2]\n",
    "biases = [b1, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = network(weights=weights, biases=biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90873096, 0.99442909, 0.96748325])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,1,1])\n",
    "nn.feedforward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简化\n",
    "希望可以指定网络结构， 自动生成所有的权重和偏置\n",
    "<img src='https://cdn.jsdelivr.net/gh/HuangJiaLian/DataBase0@master/uPic/2021_11_17_10_nn_.svg' width='20%'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [5, 3, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7828296008484752"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.normal(size=(3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63517894, -0.30112538,  0.77246912,  0.92998655, -0.74307193],\n",
       "       [ 0.65238144, -1.07640628, -0.07928429,  0.84383202,  0.17976879],\n",
       "       [ 1.71631829,  0.17039666,  0.71152783, -0.25025515, -1.77773882]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = np.random.normal(size=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22028428,  0.80460953, -0.10819366],\n",
       "       [ 0.57309653,  0.63714429,  0.16220571]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [W1, W2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.63517894, -0.30112538,  0.77246912,  0.92998655, -0.74307193],\n",
       "        [ 0.65238144, -1.07640628, -0.07928429,  0.84383202,  0.17976879],\n",
       "        [ 1.71631829,  0.17039666,  0.71152783, -0.25025515, -1.77773882]]),\n",
       " array([[ 0.22028428,  0.80460953, -0.10819366],\n",
       "        [ 0.57309653,  0.63714429,  0.16220571]])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = len(sizes)\n",
    "weights = [np.random.normal(size=(sizes[i], sizes[i-1])) for i in range(1, num_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.16525137,  0.45260646,  1.83457335,  1.55202213,  0.5027119 ],\n",
       "        [-0.34194825,  1.69494916, -0.3554959 ,  0.21895581,  0.15427267],\n",
       "        [ 0.07886147,  0.16854758,  0.69666754,  1.00795803, -0.67103703]]),\n",
       " array([[ 1.31096503,  0.34632655, -0.29357951],\n",
       "        [-0.73977153,  0.47915016, -0.35329029]])]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = [np.random.normal(size=sizes[i]) for i in range(1, num_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.80381805, 0.36686428, 0.34268272]),\n",
       " array([-1.04753967,  0.52896773])]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(self.sizes)\n",
    "        self.weights = [np.random.normal(size=(self.sizes[i], self.sizes[i-1])) for i in range(1, self.num_layers)]\n",
    "        self.biases = [np.random.normal(size=self.sizes[i]) for i in range(1, self.num_layers)]\n",
    "    \n",
    "    def feedforward(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            a = self.activation_f(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    def activation_f(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [5, 3, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = network(sizes = sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.57963283, -1.4291595 ,  1.56536723, -0.86858372,  0.68748518],\n",
       "        [ 0.18771192,  1.07509407, -0.1035565 , -1.24092079,  0.4535481 ],\n",
       "        [ 0.26993614, -0.37178654,  0.09241692, -1.24874258,  0.52227025]]),\n",
       " array([[ 1.12197696, -0.42070989, -0.98668979],\n",
       "        [-0.35485796, -2.44669371,  0.34715587]])]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.46921609, -0.28504425,  0.56630662]),\n",
       " array([ 0.15276386, -0.93573731])]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51525375, 0.09651944])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.feedforward(a=np.ones(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此神经网络的前向传播过程就完成了， 按照道理来说我们**有合适的weights和biases**就可以帮我们识别手写字符了。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 识别数字\n",
    "我们先假设有这些合适的weights和biases。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据 得到一张图片的数据\n",
    "import gzip\n",
    "import pickle\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "training_data, validation_data, test_data = pickle.load(f, encoding=\"latin1\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training_data\n",
    "# type(training_data)\n",
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 8, 4, 8])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys  = training_data[0], training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 8, 4, 8])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(ys):\n",
    "    b = np.zeros((ys.size, ys.max()+1))\n",
    "    b[np.arange(ys.size),ys] = 1\n",
    "    return b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys =  one_hot(ys = ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_test, ys_test  = test_data[0], one_hot(ys=test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 30\n",
    "x = training_data[0][i]\n",
    "# # 可视化这张图。是二维的，因此要重新排列数据\n",
    "plt.imshow(x.reshape((28,28)), cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 准备网络\n",
    "net = network(sizes = [784, 30, 10])\n",
    "# net.sizes\n",
    "# net.num_layers\n",
    "# net.biases\n",
    "# net.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net.feedforward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43370703, 0.02231803, 0.59226513, 0.70944383, 0.57134006,\n",
       "       0.43263084, 0.27787258, 0.1382496 , 0.01999872, 0.14685452])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用随机参数， 识别出的数字是: 3\n"
     ]
    }
   ],
   "source": [
    "plt.bar(np.arange(10),  out)\n",
    "plt.show()\n",
    "print('使用随机参数， 识别出的数字是: {}'.format(np.argmax(out)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不对的原因是我们的权重和偏置是随机的， 接下来我们从某个地方拿到这组参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('nn_model_weights.dat', \"rb\") as f:\n",
    "    good_weights = pickle.load(f)\n",
    "\n",
    "with open('nn_model_biases.dat', \"rb\") as f:\n",
    "    Bs = pickle.load(f)\n",
    "    good_biases = [B.flatten() for B in Bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 784)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_biases[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(net.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 784)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(net.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用最优的权重和偏置取替换掉原本随机的值\n",
    "net.weights = good_weights\n",
    "net.biases = good_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用较好参数后， 识别出的数字是: 3\n"
     ]
    }
   ],
   "source": [
    "out = net.feedforward(x)\n",
    "plt.bar(np.arange(10),  out)\n",
    "plt.show()\n",
    "print('使用较好参数后， 识别出的数字是: {}'.format(np.argmax(out)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算准确度( Accuracy)\n",
    "\n",
    "$$\n",
    "\\text{acc} = \\frac{\\text{预测正确的图片数目}}{\\text{预测图片数目}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(self.sizes)\n",
    "        self.weights = [np.random.normal(size=(self.sizes[i], self.sizes[i-1])) for i in range(1, self.num_layers)]\n",
    "        self.biases = [np.random.normal(size=self.sizes[i]) for i in range(1, self.num_layers)]\n",
    "    \n",
    "    def out(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            a = self.activation_f(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    def activation_f(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "    \n",
    "    # 计算准确度， 其中标签ys是one-hot格式\n",
    "    def acc(self, xs, ys):\n",
    "        num = xs.shape[0]\n",
    "        outs = [np.argmax(self.out(x)) for x in xs]\n",
    "        ys = [np.argmax(y) for y in ys]\n",
    "        correct_num = sum(int(out == y) for out, y in zip(outs, ys))\n",
    "        acc = correct_num / num\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = network(sizes = [784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0686"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机参数时的准确度\n",
    "net.acc(xs=xs_test, ys=ys_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.weights = good_weights\n",
    "net.biases = good_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9379"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 较优参数时的准确度\n",
    "net.acc(xs=xs_test, ys=ys_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找出这组好的参数\n",
    "定义了一个损失函数:\n",
    "$$\n",
    "C(w, b) \\equiv \\frac{1}{n} \\sum_{x} C_{x} = \\frac{1}{2 n} \\sum_{x}\\|y(x)-a_{w,b}(x)\\|^{2}\n",
    "$$\n",
    "我们的目的是找到这些好的参数, 满足:\n",
    "\n",
    "$$\n",
    "w^{*}, b^{*}=\\arg \\min _{w, b} C(w,b)\n",
    "$$\n",
    "\n",
    "<img src='https://cdn.jsdelivr.net/gh/HuangJiaLian/DataBase0@master/uPic/2021_11_17_15_grediant.png' width = '50%'/>\n",
    "\n",
    "寻找的这些参数的方法是梯度下降, $v$是由所有的权重和偏置构成的一个高维的向量， 其改变的反向就是损失函数梯度下降的方向。\n",
    "\n",
    "$$\n",
    "v \\rightarrow v^{\\prime}=v-\\eta \\nabla C\n",
    "$$\n",
    "\n",
    "具体到其中的某一个分量的更新方法是,\n",
    "\n",
    "$$\n",
    "w_{k} \\rightarrow w_{k}^{\\prime}=w_{k}-\\eta \\frac{\\partial C}{\\partial w_{k}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_{l} \\rightarrow b_{l}^{\\prime}=b_{l}-\\eta \\frac{\\partial C}{\\partial b_{l}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 随机初始化神经网络的权重和偏置之后， 相当于小球在损失函数平面上的任意位置， 假设就是上图中的初始位置A。\n",
    "- 我们加载一组比较好的权重和偏置之后， 相当于小球在损失函数平面上较低的位置， 假设就是上图中的最佳位置B。\n",
    "- 机器学习就是从A走到B的这么一个过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(self.sizes)\n",
    "        self.weights = [np.random.normal(size=(self.sizes[i], self.sizes[i-1])) for i in range(1, self.num_layers)]\n",
    "        self.biases = [np.random.normal(size=self.sizes[i]) for i in range(1, self.num_layers)]\n",
    "    \n",
    "    # 前向传播\n",
    "    def out(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            a = self.activation_f(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    # 激活函数\n",
    "    def activation_f(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "    \n",
    "    # 准确度， 其中标签ys是one-hot格式\n",
    "    def acc(self, xs, ys):\n",
    "        num = xs.shape[0]\n",
    "        outs = [np.argmax(self.out(x)) for x in xs]\n",
    "        ys = [np.argmax(y) for y in ys]\n",
    "        correct_num = sum(int(out == y) for out, y in zip(outs, ys))\n",
    "        acc = correct_num / num\n",
    "        return acc\n",
    "    \n",
    "    # 损失函数\n",
    "    def loss(self, xs, ys):\n",
    "        num_samples = len(xs)\n",
    "        loss = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            out = self.out(x)\n",
    "            v = y - out \n",
    "            loss = loss + v.dot(v)\n",
    "        loss = loss / (2*num_samples)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = network(sizes = [784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算随机参数时的损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = net.loss(xs=xs, ys=ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8253013009024597"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算较优参数时的损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.weights = good_weights\n",
    "net.biases = good_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = net.loss(xs=xs, ys=ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043179193159425984"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更新参数\n",
    "$$\n",
    "w_{k} \\rightarrow w_{k}^{\\prime}=w_{k}-\\eta \\frac{\\partial C}{\\partial w_{k}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_{l} \\rightarrow b_{l}^{\\prime}=b_{l}-\\eta \\frac{\\partial C}{\\partial b_{l}}\n",
    "$$\n",
    "\n",
    "[反向传播详细推导](https://github.com/way2ml/ML-Course/blob/main/src/backpropagation.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    \n",
    "    # 神经网络的基本属性\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(self.sizes)\n",
    "        self.weights = [np.random.normal(size=(self.sizes[i], self.sizes[i-1])) for i in range(1, self.num_layers)]\n",
    "        self.biases = [np.random.normal(size=self.sizes[i]) for i in range(1, self.num_layers)]\n",
    "    \n",
    "    # 前向传播计算输出\n",
    "    def out(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            a = self.activation_f(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    # 激活函数\n",
    "    def activation_f(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "    \n",
    "    # 激活函数的倒数 (反向传播的时候会用到)\n",
    "    def activation_f_prime(self, z):\n",
    "        return self.activation_f(z)*(1-self.activation_f(z))\n",
    "    \n",
    "    # 损失函数\n",
    "    def loss(self, xs, ys):\n",
    "        num_samples = len(xs)\n",
    "        loss = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            out = self.out(x)\n",
    "            v = y - out \n",
    "            loss = loss + v.dot(v)\n",
    "        loss = loss / (2*num_samples)\n",
    "        return loss\n",
    "    \n",
    "    # 准确度， 其中标签ys是one-hot格式\n",
    "    def acc(self, xs, ys):\n",
    "        num = xs.shape[0]\n",
    "        outs = [np.argmax(self.out(x)) for x in xs]\n",
    "        ys = [np.argmax(y) for y in ys]\n",
    "        correct_num = sum(int(out == y) for out, y in zip(outs, ys))\n",
    "        acc = correct_num / num\n",
    "        return acc\n",
    "    \n",
    "    # 更新参数\n",
    "    def update(self, lr, xs, ys):\n",
    "        # 目的: 找到要更新的量(要微调的量)\n",
    "        nabla_ws = [np.zeros(w.shape) for w in self.weights]\n",
    "        nabla_bs = [np.zeros(b.shape) for b in self.biases]\n",
    "        partial_zs = [np.zeros(b.shape) for b in self.biases]\n",
    "        \n",
    "        # 循环所有训练数据\n",
    "        for x, y in zip(xs, ys):\n",
    "            num_samples = xs.shape[0]\n",
    "            # 前向传播得到每一层的加权求和值z, 与每一层的输出(激活)值a\n",
    "            zs = []\n",
    "            a = x\n",
    "            a_s = [x]\n",
    "            # 循环所有层\n",
    "            for w, b in zip(self.weights, self.biases):\n",
    "                z = np.dot(w, a) + b\n",
    "                a = self.activation_f(z)\n",
    "                zs.append(z)\n",
    "                a_s.append(a)\n",
    "            \n",
    "            # 循环结束后的a即为网络的输出o\n",
    "            o = a_s[-1]\n",
    "            \n",
    "            # 计算梯度\n",
    "            # 最后一层\n",
    "            partial_z = (o - y)*self.activation_f_prime(zs[-1])\n",
    "            partial_zs[-1] = partial_z\n",
    "            \n",
    "            repetitions = self.sizes[-1]\n",
    "            ma = np.transpose([a_s[-2]] * repetitions)\n",
    "            nabla_ws[-1] +=  (ma* partial_zs[-1]).T\n",
    "            nabla_bs[-1] += partial_zs[-1]\n",
    "            # 反向传播 \n",
    "            # 输入层没有加权求和过激活等运算\n",
    "            for n in range(1, self.num_layers -1): \n",
    "                h,  i,  j = -n-2,  -n-1,  -n\n",
    "                partial_z = self.activation_f_prime(zs[i]) * np.dot(self.weights[j].T, partial_zs[j])\n",
    "                partial_zs[i] = partial_z\n",
    "                repetitions = self.sizes[i]\n",
    "                ma = np.transpose([a_s[h]] * repetitions)\n",
    "                nabla_ws[i] +=  (ma* partial_zs[i]).T\n",
    "                nabla_bs[i] += partial_zs[i]\n",
    "        # 更新参数， 使得网络的性能变得更好\n",
    "        # weight 是一个2D的numpy array, weights 是一个列表\n",
    "        # biase 是一个1D的numpy array， biases是一个列表\n",
    "        self.weights = [weight - (lr/num_samples) * nabla_w for weight, nabla_w in zip(self.weights, nabla_ws)]\n",
    "        self.biases = [biase - (lr/num_samples) * nabla_b  for biase,  nabla_b in zip(self.biases, nabla_bs)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = network(sizes = [784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1466383674132503 0.07044\n",
      "0.9394941594433865 0.07322\n",
      "0.791047275235436 0.075\n",
      "0.6983553968382673 0.0769\n",
      "0.6426249963945441 0.07816\n",
      "0.6076381979479398 0.07932\n",
      "0.5842599635610904 0.0802\n",
      "0.5677777442404874 0.08138\n",
      "0.5556565296874889 0.08238\n",
      "0.5464399277685607 0.08376\n"
     ]
    }
   ],
   "source": [
    "# Training \n",
    "for i in range(10):\n",
    "    net.update( lr=1, xs=xs, ys=ys)\n",
    "    print(net.loss(xs=xs, ys=ys), net.acc(xs=xs, ys=ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    \n",
    "    # 神经网络的基本属性\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(self.sizes)\n",
    "        self.weights = [np.random.normal(size=(self.sizes[i], self.sizes[i-1])) for i in range(1, self.num_layers)]\n",
    "        self.biases = [np.random.normal(size=self.sizes[i]) for i in range(1, self.num_layers)]\n",
    "    # 前向传播计算输出\n",
    "    def out(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            a = self.activation_f(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    # 激活函数\n",
    "    def activation_f(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "    \n",
    "    # 激活函数的倒数 (反向传播的时候会用到)\n",
    "    def activation_f_prime(self, z):\n",
    "        return self.activation_f(z)*(1-self.activation_f(z))\n",
    "    \n",
    "    # 损失函数\n",
    "    def loss(self, xs, ys):\n",
    "        num_samples = len(xs)\n",
    "        loss = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            out = self.out(x)\n",
    "            v = y - out \n",
    "            loss = loss + v.dot(v)\n",
    "        loss = loss / (2*num_samples)\n",
    "        return loss\n",
    "    \n",
    "    # 准确度， 其中标签ys是one-hot格式\n",
    "    def acc(self, xs, ys):\n",
    "        num = xs.shape[0]\n",
    "        outs = [np.argmax(self.out(x)) for x in xs]\n",
    "        ys = [np.argmax(y) for y in ys]\n",
    "        correct_num = sum(int(out == y) for out, y in zip(outs, ys))\n",
    "        acc = correct_num / num\n",
    "        return acc\n",
    "    \n",
    "    # 更新参数\n",
    "    def update(self, lr, xs, ys):\n",
    "        # 目的: 找到要更新的量(要微调的量)\n",
    "        nabla_ws = [np.zeros(w.shape) for w in self.weights]\n",
    "        nabla_bs = [np.zeros(b.shape) for b in self.biases]\n",
    "        partial_zs = [np.zeros(b.shape) for b in self.biases]\n",
    "        \n",
    "        # 循环所有训练数据\n",
    "        for x, y in zip(xs, ys):\n",
    "            num_samples = xs.shape[0]\n",
    "            # 前向传播得到每一层的加权求和值z, 与每一层的输出(激活)值a\n",
    "            zs = []\n",
    "            a = x\n",
    "            a_s = [x]\n",
    "            # 循环所有层\n",
    "            for w, b in zip(self.weights, self.biases):\n",
    "                z = np.dot(w, a) + b\n",
    "                a = self.activation_f(z)\n",
    "                zs.append(z)\n",
    "                a_s.append(a)\n",
    "            \n",
    "            # 循环结束后的a即为网络的输出o\n",
    "            o = a_s[-1]\n",
    "            \n",
    "            # 计算梯度\n",
    "            # 最后一层\n",
    "            partial_z = (o - y)*self.activation_f_prime(zs[-1])\n",
    "            partial_zs[-1] = partial_z\n",
    "            \n",
    "            repetitions = self.sizes[-1]\n",
    "            ma = np.transpose([a_s[-2]] * repetitions)\n",
    "            nabla_ws[-1] +=  (ma* partial_zs[-1]).T\n",
    "            nabla_bs[-1] += partial_zs[-1]\n",
    "            # 反向传播 \n",
    "            # 输入层没有加权求和过激活等运算\n",
    "            for n in range(1, self.num_layers -1): \n",
    "                h,  i,  j = -n-2,  -n-1,  -n\n",
    "                partial_z = self.activation_f_prime(zs[i]) * np.dot(self.weights[j].T, partial_zs[j])\n",
    "                partial_zs[i] = partial_z\n",
    "                repetitions = self.sizes[i]\n",
    "                ma = np.transpose([a_s[h]] * repetitions)\n",
    "                nabla_ws[i] +=  (ma* partial_zs[i]).T\n",
    "                nabla_bs[i] += partial_zs[i]\n",
    "        # 更新参数， 使得网络的性能变得更好\n",
    "        # weight 是一个2D的numpy array, weights 是一个列表\n",
    "        # biase 是一个1D的numpy array， biases是一个列表\n",
    "        self.weights = [weight - (lr/num_samples) * nabla_w for weight, nabla_w in zip(self.weights, nabla_ws)]\n",
    "        self.biases = [biase - (lr/num_samples) * nabla_b  for biase,  nabla_b in zip(self.biases, nabla_bs)] \n",
    "        \n",
    "    def sgd(self, xs, ys, lr, epochs, batch_size):\n",
    "        assert xs.shape[0] == ys.shape[0]\n",
    "        \n",
    "        #  打乱顺序\n",
    "        p = np.random.permutation(xs.shape[0])\n",
    "        xs, ys = xs[p], ys[p]\n",
    "        \n",
    "        # 一大堆训练数据分成很多小份\n",
    "        n = xs.shape[0]\n",
    "        xs_batches = [ xs[k:k+batch_size] for k in range(0, n, batch_size)]\n",
    "        ys_batches = [ ys[k:k+batch_size] for k in range(0, n, batch_size)]\n",
    "        for epoch in range(epochs):\n",
    "            for xs_batch, ys_batch in zip(xs_batches, ys_batches):\n",
    "                # 用一小份数据去更新参数\n",
    "                self.update(lr=lr, xs=xs_batch, ys=ys_batch)\n",
    "            loss = self.loss(xs=xs, ys=ys)\n",
    "            acc = self.acc(xs=xs, ys=ys)\n",
    "            print('epoch: {:<5}\\t loss: {:.4f}\\t acc: {:.4f}'.format(epoch+1, loss, acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = network(sizes = [784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1    \t loss: 0.2645\t acc: 0.5805\n",
      "epoch: 2    \t loss: 0.1438\t acc: 0.8240\n",
      "epoch: 3    \t loss: 0.1118\t acc: 0.8644\n",
      "epoch: 4    \t loss: 0.0968\t acc: 0.8828\n",
      "epoch: 5    \t loss: 0.0874\t acc: 0.8952\n",
      "epoch: 6    \t loss: 0.0808\t acc: 0.9027\n",
      "epoch: 7    \t loss: 0.0759\t acc: 0.9079\n",
      "epoch: 8    \t loss: 0.0721\t acc: 0.9132\n",
      "epoch: 9    \t loss: 0.0689\t acc: 0.9169\n",
      "epoch: 10   \t loss: 0.0660\t acc: 0.9200\n"
     ]
    }
   ],
   "source": [
    "net.sgd(xs=xs, ys=ys, lr=1, epochs=10, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    # 神经网络的基本属性\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(self.sizes)\n",
    "        self.weights = [np.random.normal(size=(self.sizes[i], self.sizes[i-1])) for i in range(1, self.num_layers)]\n",
    "        self.biases = [np.random.normal(size=self.sizes[i]) for i in range(1, self.num_layers)]\n",
    "    \n",
    "    # 前向传播计算输出\n",
    "    def out(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            a = self.activation_f(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    # 激活函数\n",
    "    def activation_f(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "    \n",
    "    # 激活函数的倒数 (反向传播的时候会用到)\n",
    "    def activation_f_prime(self, z):\n",
    "        return self.activation_f(z)*(1-self.activation_f(z))\n",
    "    \n",
    "    # 损失函数\n",
    "    def loss(self, xs, ys):\n",
    "        num_samples = len(xs)\n",
    "        loss = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            out = self.out(x)\n",
    "            v = y - out \n",
    "            loss = loss + v.dot(v)\n",
    "        loss = loss / (2*num_samples)\n",
    "        return loss\n",
    "    \n",
    "    # 准确度， 其中标签ys是one-hot格式\n",
    "    def acc(self, xs, ys):\n",
    "        num = xs.shape[0]\n",
    "        outs = [np.argmax(self.out(x)) for x in xs]\n",
    "        ys = [np.argmax(y) for y in ys]\n",
    "        correct_num = sum(int(out == y) for out, y in zip(outs, ys))\n",
    "        acc = correct_num / num\n",
    "        return acc\n",
    "    \n",
    "    def backprop(self, x, y):\n",
    "        # 目的: 找到要更新的量(要微调的量)\n",
    "        nabla_ws = [np.zeros(w.shape) for w in self.weights]\n",
    "        nabla_bs = [np.zeros(b.shape) for b in self.biases]\n",
    "        \n",
    "        partial_zs = [np.zeros(b.shape) for b in self.biases]\n",
    "        # 前向传播得到每一层的加权求和值z, 与每一层的输出(激活)值a\n",
    "        zs = []\n",
    "        a = x\n",
    "        a_s = [x]\n",
    "        # 循环所有层\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(w, a) + b\n",
    "            a = self.activation_f(z)\n",
    "            zs.append(z)\n",
    "            a_s.append(a)\n",
    "\n",
    "        # 循环结束后的a即为网络的输出o\n",
    "        o = a_s[-1]\n",
    "\n",
    "        # 计算梯度\n",
    "        # 对最后一层\n",
    "        partial_z = (o - y)*self.activation_f_prime(zs[-1])\n",
    "        partial_zs[-1] = partial_z\n",
    "\n",
    "        nabla_ws[-1] =  (a_s[-2].reshape((-1, 1))* partial_zs[-1].reshape((1, -1))).T\n",
    "        nabla_bs[-1] = partial_zs[-1]\n",
    "        # 反向传播 \n",
    "        # 输入层没有加权求和过激活等运算\n",
    "        for n in range(1, self.num_layers -1): \n",
    "            h,  i,  j = -n-2,  -n-1,  -n\n",
    "            partial_z = self.activation_f_prime(zs[i]) * np.dot(self.weights[j].T, partial_zs[j])\n",
    "            partial_zs[i] = partial_z\n",
    "            nabla_ws[i] =  (a_s[h].reshape((-1, 1))* partial_zs[i].reshape((1, -1))).T\n",
    "            nabla_bs[i] = partial_zs[i]       \n",
    "        return nabla_ws, nabla_bs\n",
    "    \n",
    "    # 更新参数\n",
    "    def update(self, lr, xs, ys):\n",
    "        \n",
    "        # 训练样本的数目\n",
    "        num_samples = xs.shape[0]\n",
    "        \n",
    "        # 目的: 找到要更新的量\n",
    "        nabla_ws = [np.zeros(w.shape) for w in self.weights]\n",
    "        nabla_bs = [np.zeros(b.shape) for b in self.biases]\n",
    "        \n",
    "        \n",
    "        # 循环所有训练数据\n",
    "        for x, y in zip(xs, ys):\n",
    "            delta_nabla_ws, delta_nabla_bs = self.backprop(x,y)\n",
    "            nabla_ws = [nw+dnw for nw, dnw in zip(nabla_ws, delta_nabla_ws)]\n",
    "            nabla_bs= [nb+dnb for nb, dnb in zip(nabla_bs, delta_nabla_bs)]\n",
    "        \n",
    "        # 更新参数， 使得网络的性能变得更好\n",
    "        self.weights = [weight - (lr/num_samples) * nabla_w for weight, nabla_w in zip(self.weights, nabla_ws)]\n",
    "        self.biases = [biase - (lr/num_samples) * nabla_b  for biase,  nabla_b in zip(self.biases, nabla_bs)] \n",
    "        \n",
    "    def sgd(self, xs, ys, lr, epochs, batch_size):\n",
    "        assert xs.shape[0] == ys.shape[0]\n",
    "        \n",
    "        #  打乱顺序\n",
    "        p = np.random.permutation(xs.shape[0])\n",
    "        xs, ys = xs[p], ys[p]\n",
    "        \n",
    "        # 一大堆训练数据分成很多小份\n",
    "        n = xs.shape[0]\n",
    "        xs_batches = [ xs[k:k+batch_size] for k in range(0, n, batch_size)]\n",
    "        ys_batches = [ ys[k:k+batch_size] for k in range(0, n, batch_size)]\n",
    "        for epoch in range(epochs):\n",
    "            for xs_batch, ys_batch in zip(xs_batches, ys_batches):\n",
    "                # 用一小份数据去更新参数\n",
    "                self.update(lr=lr, xs=xs_batch, ys=ys_batch)\n",
    "            loss = self.loss(xs=xs, ys=ys)\n",
    "            acc = self.acc(xs=xs, ys=ys)\n",
    "            print('epoch: {:<5}\\t loss: {:.4f}\\t acc: {:.4f}'.format(epoch+1, loss, acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = network(sizes = [784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1    \t loss: 0.1943\t acc: 0.7358\n",
      "epoch: 2    \t loss: 0.1535\t acc: 0.7895\n",
      "epoch: 3    \t loss: 0.1371\t acc: 0.8090\n",
      "epoch: 4    \t loss: 0.1272\t acc: 0.8196\n",
      "epoch: 5    \t loss: 0.1209\t acc: 0.8269\n",
      "epoch: 6    \t loss: 0.1161\t acc: 0.8314\n",
      "epoch: 7    \t loss: 0.1124\t acc: 0.8344\n",
      "epoch: 8    \t loss: 0.1093\t acc: 0.8375\n",
      "epoch: 9    \t loss: 0.1067\t acc: 0.8401\n",
      "epoch: 10   \t loss: 0.1045\t acc: 0.8422\n"
     ]
    }
   ],
   "source": [
    "net.sgd(xs=xs, ys=ys, lr=1, epochs=10, batch_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 接下来"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**理论**:\n",
    "\n",
    "- Hung-yi Lee 机器学习课程 https://www.youtube.com/c/HungyiLeeNTU\n",
    "\n",
    "\n",
    "**工具**:\n",
    "\n",
    "- https://www.tensorflow.org/\n",
    "<img src='https://www.gstatic.com/devrel-devsite/prod/v83c28b42a9d2de845cf6ea5b33e8c3314f0e1ea60229353829f7578993509959/tensorflow/images/lockup.svg' width='40%'/>\n",
    "- 或者 https://pytorch.org/ \n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/9/96/Pytorch_logo.png' width='40%'>\n",
    "\n",
    "\n",
    "**讨论**:\n",
    "\n",
    "- 课程讨论 https://github.com/way2ml/forum/discussions/13\n",
    "<img src='https://raw.githubusercontent.com/way2ml/forum/main/logo/forum_logo.png' width='50%'>\n",
    "- way2ml: https://www.way2ml.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 谢谢大家"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
