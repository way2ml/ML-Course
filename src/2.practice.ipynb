{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度神经网络入门 --实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 神经元\n",
    "![](https://cdn.jsdelivr.net/gh/HuangJiaLian/DataBase0@master/uPic/2021_11_07_18_2021_11_01_11_3CIDZe.jpg)\n",
    "\n",
    "面向对象的思维\n",
    "\n",
    "单个神经元的\n",
    "- 属性有哪些?\n",
    "- 功能有什么?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 先加权求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = 0.1\n",
    "x2 = 0.5\n",
    "x3 = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 也可以这样， 一次性赋值\n",
    "w1, w2, w3 = 2, 1, 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = w1 * x1 + w2*x2 + w3*x3 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第三方库的导入\n",
    "# 简化一点\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://numpy.org/doc/stable/_static/numpylogo.svg)](https://numpy.org/doc/stable/user/whatisnumpy.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.5 0.8]\n",
      "[2.  1.  0.5]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([x1, x2, x3])\n",
    "w = np.array([w1, w2, w3])\n",
    "print(x)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6\n"
     ]
    }
   ],
   "source": [
    "z = np.dot(x, w) + b\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 说明文档\n",
    "`numpy.dot`的[参考说明](https://numpy.org/doc/stable/reference/generated/numpy.dot.html)\n",
    "\n",
    "- 分一维和二维\n",
    "- 不用记忆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 激活函数\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1+e^{-z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数定义\n",
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid 激活函数\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列表: 画出激活函数的图像\n",
    "z_s = [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新建空的列表\n",
    "a_s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取 z_s 里面的每一个数(第1个， 第3个， 最后一个， 倒数第2个， 从第二个开始到最后)\n",
    "z_s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# 循环: 方法1\n",
    "# 取 z_s 里面的每一个数\n",
    "for z in z_s:\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0066928509242848554\n",
      "0.01798620996209156\n",
      "0.04742587317756678\n",
      "0.11920292202211755\n",
      "0.2689414213699951\n",
      "0.5\n",
      "0.7310585786300049\n",
      "0.8807970779778823\n",
      "0.9525741268224334\n",
      "0.9820137900379085\n",
      "0.9933071490757153\n"
     ]
    }
   ],
   "source": [
    "# 循环\n",
    "for z in z_s:\n",
    "    a = sigmoid(z)\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# 循环: 方法2, 用索引号\n",
    "# 取 z_s 里面的每一个数\n",
    "num = len(z_s)\n",
    "for i in range(num):\n",
    "    print(z_s[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in z_s:\n",
    "    a = sigmoid(z)\n",
    "    a_s.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0066928509242848554,\n",
       " 0.01798620996209156,\n",
       " 0.04742587317756678,\n",
       " 0.11920292202211755,\n",
       " 0.2689414213699951,\n",
       " 0.5,\n",
       " 0.7310585786300049,\n",
       " 0.8807970779778823,\n",
       " 0.9525741268224334,\n",
       " 0.9820137900379085,\n",
       " 0.9933071490757153]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作图\n",
    "[<img src='https://matplotlib.org/_static/images/logo2.svg' width='40%'>](https://matplotlib.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(z_s, a_s)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('$\\sigma (z)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简化一点: 不用循环\n",
    "# 利用Numpy这种element-wize的计算特性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_s = np.array([-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_s = sigmoid(z_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00669285 0.01798621 0.04742587 0.11920292 0.26894142 0.5\n",
      " 0.73105858 0.88079708 0.95257413 0.98201379 0.99330715] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(a_s, type(a_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z_s, a_s)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('$\\sigma (z)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 综合一下: 单个神经元的计算\n",
    "output = np.dot(x, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sigmoid(np.dot(x, w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973403006423134\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  面向对象的写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义神经元 类\n",
    "class neuron:\n",
    "    def __init__(self, x, w, b):\n",
    "        self.x = x\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "    \n",
    "    def out(self):\n",
    "        return self.sigmoid(np.dot(self.w, self.x) + self.b)\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = neuron(x=x, w=w, b=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.973403006423134"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1.out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 神经层\n",
    "<img src='https://cdn.jsdelivr.net/gh/HuangJiaLian/DataBase0@master/uPic/2021_11_18_22_nn.png' width='40%'/>\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{l}a_{20} \\\\ a_{21}  \\end{array}\\right]= \n",
    "\\sigma \\left ( \\left[\\begin{array}{llll}\n",
    "w_{00} & w_{01} & w_{02}\\\\ \n",
    "w_{10} & w_{11} & w_{12}\\\\ \n",
    "\\end{array}\\right]\\left[\\begin{array}{l}a_{10} \\\\ a_{11} \\\\ a_{12} \\end{array}\\right]+\\left[\\begin{array}{l}b_{20} \\\\ b_{21} \\end{array}\\right] \\right )\n",
    "$$\n",
    "\n",
    "一层神经元的属性有哪些?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 红色层(第二层)\n",
    "w00, w01, w02 = 1, 2, 3\n",
    "w10, w11, w12 = 2, 2, 2\n",
    "w = np.array([[w00, w01, w02], [w10, w11, w12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [2, 2, 2]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上一层的输出\n",
    "a10, a11, a12 = 1, 1 , 1\n",
    "a1 = np.array([a10, a11, a12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(w,a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = np.dot(w,a1) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 8])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = sigmoid(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99908895, 0.99966465])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(self, x, w, b):\n",
    "        self.x = x \n",
    "        self.w = w \n",
    "        self.b = b\n",
    "    \n",
    "    def out(self):\n",
    "        return self.sigmoid(np.dot(self.w, self.x) + self.b)\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = layer(x=a1, w=w, b=b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99908895, 0.99966465])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    def __init__(self, weights, biases):\n",
    "        self.weights = weights\n",
    "        self.biases = biases\n",
    "    \n",
    "    # 前向传播\n",
    "    def feedforward(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(w, a) + b\n",
    "            a = self.sigmoid(z)\n",
    "        return a\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证是否写正确了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  网络结构 sizes = [3, 3, 3]\n",
    "# 输入层\n",
    "x = np.array([1,1,1])\n",
    "a0 = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一层\n",
    "w1 = np.array([[1, 2, 1], [2, 2, 2], [1,1,3]])\n",
    "b1= np.array([1,1,2])\n",
    "# 具体化\n",
    "l_1 = layer(x=a0, w=w1, b=b1)\n",
    "# 第一层输出\n",
    "a1 = l_1.out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二层\n",
    "w2 = np.array([[0.1, 0.2, 1], [2, 0.2, 2], [1,0.1,0.3]])\n",
    "b2= np.array([1,1,2])\n",
    "l_2 = layer(x=a1, w=w2, b=b2)\n",
    "a_2 = l_2.out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90873096, 0.99442909, 0.96748325])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 用Network类去验证\n",
    "weights = [w1, w2]\n",
    "biases = [b1, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = network(weights=weights, biases=biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90873096, 0.99442909, 0.96748325])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,1,1])\n",
    "nn.feedforward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简化\n",
    "希望可以指定网络结构， 自动生成所有的权重和偏置\n",
    "<img src='https://cdn.jsdelivr.net/gh/HuangJiaLian/DataBase0@master/uPic/2021_11_17_10_nn_.svg' width='20%'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [5, 3, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8310450521329722"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.normal(size=(3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.48590585, -0.0413512 , -0.22176021, -1.0845885 , -0.44338582],\n",
       "       [-1.01239947,  0.77726441,  0.79988581,  1.87527956, -0.37930013],\n",
       "       [-0.2551936 , -0.59249843, -1.13129887,  0.47799903, -2.58317304]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = np.random.normal(size=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57544127,  1.65625026, -0.14084746],\n",
       "       [-0.48214812, -0.86049758,  0.53939317]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [W1, W2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.48590585, -0.0413512 , -0.22176021, -1.0845885 , -0.44338582],\n",
       "        [-1.01239947,  0.77726441,  0.79988581,  1.87527956, -0.37930013],\n",
       "        [-0.2551936 , -0.59249843, -1.13129887,  0.47799903, -2.58317304]]),\n",
       " array([[-0.57544127,  1.65625026, -0.14084746],\n",
       "        [-0.48214812, -0.86049758,  0.53939317]])]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = len(sizes)\n",
    "weights = [np.random.normal(size=(sizes[i], sizes[i-1])) for i in range(1, num_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.80992695, -2.35578708, -0.62446598, -0.15217514,  0.86789026],\n",
       "        [ 0.93853728, -0.22018869, -0.76142   , -0.49596161, -0.8758443 ],\n",
       "        [-0.10803761,  0.72730329,  0.02689266, -1.74352192,  0.12897703]]),\n",
       " array([[ 0.31110912,  0.28124212, -0.00530105],\n",
       "        [-0.25087207,  0.09306055,  0.60687567]])]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = [np.random.normal(size=sizes[i]) for i in range(1, num_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.26652719,  0.52964416,  0.62108237]),\n",
       " array([-0.81112241, -0.15153682])]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(self.sizes)\n",
    "        self.weights = [np.random.normal(size=(self.sizes[i], self.sizes[i-1])) for i in range(1, self.num_layers)]\n",
    "        self.biases = [np.random.normal(size=self.sizes[i]) for i in range(1, self.num_layers)]\n",
    "    \n",
    "    def feedforward(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            a = self.activation_f(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    def activation_f(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [5, 3, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = network(sizes = sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.03571827,  0.17279593, -1.57379392,  1.01743535, -1.02635771],\n",
       "        [ 1.34860769, -0.59791691, -1.92230948, -0.63998503,  0.58002192],\n",
       "        [-0.33010396, -1.5828917 ,  1.50314068, -0.83786835, -0.74404553]]),\n",
       " array([[-0.13098945, -1.36870377,  0.03163598],\n",
       "        [-1.01380884, -0.74503925, -0.23817058]])]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.96462711, -0.62452056,  0.71500555]),\n",
       " array([ 0.57528851, -1.19231486])]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59524125, 0.19245589])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.feedforward(a=np.ones(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此神经网络的前向传播过程就完成了， 按照道理来说我们**有合适的weights和biases**就可以帮我们识别手写字符了。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 识别数字\n",
    "我们先假设有这些合适的weights和biases。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据 得到一张图片的数据\n",
    "import gzip\n",
    "import pickle\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "training_data, validation_data, test_data = pickle.load(f, encoding=\"latin1\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training_data\n",
    "# type(training_data)\n",
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 8, 4, 8])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys  = training_data[0], training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 8, 4, 8])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(ys):\n",
    "    b = np.zeros((ys.size, ys.max()+1))\n",
    "    b[np.arange(ys.size),ys] = 1\n",
    "    return b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys =  one_hot(ys = ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_test, ys_test  = test_data[0], one_hot(ys=test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAOKklEQVR4nO3dbchc9ZnH8d/PrI0aKySah5s0mFpFtyqbrkFWUpYETXH1hfZFtQqi+JCCDVQQo3aVKLIoandBhGpio1FrSqMRY6lWjUW3BMQYXBOrbR6I5q7BkERS88aa5NoX94nc6j3/uTNnnpLr+4GbmTnXnHMuhvxyzpz/zPwdEQJw+Dui1w0A6A7CDiRB2IEkCDuQBGEHkvinbu7MNpf+gQ6LCI+0vNaR3fb5tv9ie6PtW+psC0BnudVxdttjJP1V0lxJg5LelHRZRPy5sA5HdqDDOnFkP1vSxojYHBH/kPQbSRfV2B6ADqoT9qmStg57PFgt+xLb82yvsb2mxr4A1FTnAt1IpwpfO02PiEWSFkmcxgO9VOfIPihp2rDH35L0Ub12AHRKnbC/KekU29+2/Q1JP5a0sj1tAWi3lk/jI2Kv7fmS/iBpjKQlEfFu2zoD0FYtD721tDPeswMd15EP1QA4dBB2IAnCDiRB2IEkCDuQBGEHkujq99mB4QYGBor1V199tVgfN25csX7zzTc3rC1btqy47uGIIzuQBGEHkiDsQBKEHUiCsANJEHYgCYbeUMvYsWOL9fvuu69h7dxzzy2ue+qpp7bU0wFbt25t/qREOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs6OWq6++ulifP39+y9v+7LPPivXVq1cX6xs2bGh534cjjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7MmdccYZxfqtt95arF9++eXFemmW4A8//LC47v3331+sP/jgg8U6vqxW2G1vkfSppH2S9kbEzHY0BaD92nFknxMRO9qwHQAdxHt2IIm6YQ9JL9l+y/a8kZ5ge57tNbbX1NwXgBrqnsbPioiPbE+S9LLt9yPi9eFPiIhFkhZJku3GV2sAdFStI3tEfFTdbpf0rKSz29EUgPZrOey2x9n+5oH7kn4gaX27GgPQXnVO4ydLetb2ge08FREvtqUrtM2UKVOK9ddee61YHz9+fLG+f//+Yn3hwoUNa4899lhx3cHBwWIdB6flsEfEZkn/0sZeAHQQQ29AEoQdSIKwA0kQdiAJwg4kwVdcDwPXXnttw9qCBQuK6zYbWtu0aVOx/vDDDxfrzb6miu7hyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOfgh49NFHi/XSWPlRRx1Va9933nlnsf7kk0/W2j66hyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHsfaPZzz7NmzWp5/bFjxxbXvfHGG4v1p556qljHoYMjO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTh7F0ycOLFYX7lyZbF+8sknt7zvZuPoDzzwQLHebEpmHDqaHtltL7G93fb6Ycsm2H7Z9obqtjzTAICeG81p/GOSzv/KslskrYqIUyStqh4D6GNNwx4Rr0va9ZXFF0laWt1fKuniNvcFoM1afc8+OSK2SVJEbLM9qdETbc+TNK/F/QBok45foIuIRZIWSZLt6PT+AIys1aG3j20PSFJ1u719LQHohFbDvlLSldX9KyU91552AHRK09N428skzZZ0gu1BSQsl3SPpt7avkfShpB91sslD3SWXXFKsz5w5s9b233///Ya1xx9/vLjuvn37au0bh46mYY+IyxqUzm1zLwA6iI/LAkkQdiAJwg4kQdiBJAg7kARfce2C2bNnF+u2a21//fr1DWs7d+6ste1OOuKI8rFm3Lhxxfqll15arJ900kkNa+vWrSuuu2zZsmL9UMSRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJy9DSZMmFCsn3baacV6RL0f8HnppZdqrV/H8ccfX6yfc845DWvNXpd77723pZ5G4/nnny/Wly9fXqzv3bu3ne10BUd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfY2mDSp4exXkqRjjz221vabffd6xYoVtbZfcsUVVxTrN910U7E+efLkhrXdu3cX1926dWuxPm3atGK9ZM6cOcX61KlTi/UPPvig5X33Ckd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfY2WLBgQbF+4okn1tr+xIkTi/XjjjuuYW3Xrl3FdRcvXlysX3XVVcV6s+91n3nmmQ1rGzduLK47Y8aMYn3t2rXFeskLL7xQrB+K4+jNND2y215ie7vt9cOW3WH7b7bfrv4u6GybAOoazWn8Y5LOH2H5/0TEjOrv9+1tC0C7NQ17RLwuqXwuCKDv1blAN9/2O9Vp/vhGT7I9z/Ya22tq7AtATa2G/ZeSviNphqRtkn7R6IkRsSgiZkbEzBb3BaANWgp7RHwcEfsiYr+kxZLObm9bANqtpbDbHhj28IeSGs8ZDKAvNB1nt71M0mxJJ9gelLRQ0mzbMySFpC2SftLBHvtes+9d1zVlypRi/YknnmhYa/ab8s2+r/70008X60uWLCnWm42ll+zZs6dY/+STT4r18eMbXkpKqWnYI+KyERb/qgO9AOggPi4LJEHYgSQIO5AEYQeSIOxAEnzFtQ1KQ1+SdPvtt3d0/7NmzWqpJjWfFvmhhx4q1rds2VKsjx07tmHttttuK667evXqYn3z5s3F+llnndWwtmnTpuK6hyOO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsbdDsK66vvPJKsX7eeee1s52D8uKLLxbrzcbRjznmmGL9jTfeaFg7/fTTi+vW9cgjjzSs3XXXXR3ddz/iyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTgiurczu3s76yNz5swp1letWtWlTr5u9+7dxfqOHTuK9TFjxhTr06dPP9iWvtBsuunnnnuuWL/77rsb1ur8xHW/iwiPtJwjO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTh7Fxx55JHF+vXXX1+sL1iwoFgfGBg46J7axR5xSPcLpX9fy5cvL67b7HXZuXNnsZ5Vy+PstqfZ/qPt92y/a/tn1fIJtl+2vaG6ZTJsoI+N5jR+r6QbI+KfJf2bpJ/a/q6kWyStiohTJK2qHgPoU03DHhHbImJtdf9TSe9JmirpIklLq6ctlXRxp5oEUN9B/Qad7emSvifpDUmTI2KbNPQfgu1JDdaZJ2levTYB1DXqsNs+VtIzkm6IiL83uzBzQEQskrSo2kbKC3RAPxjV0JvtIzUU9F9HxIpq8ce2B6r6gKTtnWkRQDs0HXrz0CF8qaRdEXHDsOX3SdoZEffYvkXShIgojhFxZG/N0UcfXaxfd911DWtz584trnvhhRe21NMBe/fuLdZL+282JfPnn3/eUk/ZNRp6G81p/CxJV0haZ/vtatnPJd0j6be2r5H0oaQftaNRAJ3RNOwR8SdJjd6gn9vedgB0Ch+XBZIg7EAShB1IgrADSRB2IAm+4gocZvgpaSA5wg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSKJp2G1Ps/1H2+/Zftf2z6rld9j+m+23q78LOt8ugFY1nSTC9oCkgYhYa/ubkt6SdLGkSyTtiYj7R70zJokAOq7RJBGjmZ99m6Rt1f1Pbb8naWp72wPQaQf1nt32dEnfk/RGtWi+7XdsL7E9vsE682yvsb2mVqcAahn1XG+2j5X0mqT/iogVtidL2iEpJN2loVP9q5tsg9N4oMMancaPKuy2j5T0O0l/iIj/HqE+XdLvIuKMJtsh7ECHtTyxo21L+pWk94YHvbpwd8APJa2v2ySAzhnN1fjvS/pfSesk7a8W/1zSZZJmaOg0foukn1QX80rb4sgOdFit0/h2IexA5zE/O5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IImmPzjZZjskfTDs8QnVsn7Ur731a18SvbWqnb2d2KjQ1e+zf23n9pqImNmzBgr6tbd+7Uuit1Z1qzdO44EkCDuQRK/DvqjH+y/p1976tS+J3lrVld56+p4dQPf0+sgOoEsIO5BET8Ju+3zbf7G90fYtveihEdtbbK+rpqHu6fx01Rx6222vH7Zsgu2XbW+obkecY69HvfXFNN6FacZ7+tr1evrzrr9ntz1G0l8lzZU0KOlNSZdFxJ+72kgDtrdImhkRPf8Ahu1/l7RH0uMHptayfa+kXRFxT/Uf5fiIuLlPertDBzmNd4d6azTN+FXq4WvXzunPW9GLI/vZkjZGxOaI+Iek30i6qAd99L2IeF3Srq8svkjS0ur+Ug39Y+m6Br31hYjYFhFrq/ufSjowzXhPX7tCX13Ri7BPlbR12ONB9dd87yHpJdtv2Z7X62ZGMPnANFvV7aQe9/NVTafx7qavTDPeN69dK9Of19WLsI80NU0/jf/Nioh/lfQfkn5ana5idH4p6TsamgNwm6Rf9LKZaprxZyTdEBF/72Uvw43QV1det16EfVDStGGPvyXpox70MaKI+Ki63S7pWQ297egnHx+YQbe63d7jfr4QER9HxL6I2C9psXr42lXTjD8j6dcRsaJa3PPXbqS+uvW69SLsb0o6xfa3bX9D0o8lrexBH19je1x14US2x0n6gfpvKuqVkq6s7l8p6bke9vIl/TKNd6NpxtXj167n059HRNf/JF2goSvymyT9Zy96aNDXSZL+r/p7t9e9SVqmodO6zzV0RnSNpOMlrZK0obqd0Ee9PaGhqb3f0VCwBnrU2/c19NbwHUlvV38X9Pq1K/TVldeNj8sCSfAJOiAJwg4kQdiBJAg7kARhB5Ig7EAShB1I4v8BnhRPam3gXygAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 90\n",
    "\n",
    "x = training_data[0][i]\n",
    "# 可视化这张图。是二维的，因此要重新排列数据\n",
    "plt.imshow(x.reshape((28,28)), cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 准备网络\n",
    "net = network(sizes = [784, 30, 10])\n",
    "# net.sizes\n",
    "# net.num_layers\n",
    "# net.biases\n",
    "# net.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net.feedforward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26797976, 0.88543005, 0.93361941, 0.00327054, 0.30739191,\n",
       "       0.99907645, 0.9918942 , 0.10713712, 0.36794101, 0.19951928])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用随机参数， 识别出的数字是: 5\n"
     ]
    }
   ],
   "source": [
    "plt.bar(np.arange(10),  out)\n",
    "plt.show()\n",
    "print('使用随机参数， 识别出的数字是: {}'.format(np.argmax(out)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不对的原因是我们的权重和偏置是随机的， 接下来我们从某个地方拿到这组参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('nn_model_weights.dat', \"rb\") as f:\n",
    "    good_weights = pickle.load(f)\n",
    "\n",
    "with open('nn_model_biases.dat', \"rb\") as f:\n",
    "    Bs = pickle.load(f)\n",
    "    good_biases = [B.flatten() for B in Bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 784)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_biases[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(net.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 784)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(net.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用最优的权重和偏置取替换掉原本随机的值\n",
    "net.weights = good_weights\n",
    "net.biases = good_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用较好参数后， 识别出的数字是: 6\n"
     ]
    }
   ],
   "source": [
    "out = net.feedforward(x)\n",
    "plt.bar(np.arange(10),  out)\n",
    "plt.show()\n",
    "print('使用较好参数后， 识别出的数字是: {}'.format(np.argmax(out)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算准确度( Accuracy)\n",
    "\n",
    "$$\n",
    "\\text{acc} = \\frac{\\text{预测正确的图片数目}}{\\text{预测图片数目}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(self.sizes)\n",
    "        self.weights = [np.random.normal(size=(self.sizes[i], self.sizes[i-1])) for i in range(1, self.num_layers)]\n",
    "        self.biases = [np.random.normal(size=self.sizes[i]) for i in range(1, self.num_layers)]\n",
    "    \n",
    "    def out(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            a = self.activation_f(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    def activation_f(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "    \n",
    "    # 计算准确度， 其中标签ys是one-hot格式\n",
    "    def acc(self, xs, ys):\n",
    "        num = xs.shape[0]\n",
    "        outs = [np.argmax(self.out(x)) for x in xs]\n",
    "        ys = [np.argmax(y) for y in ys]\n",
    "        correct_num = sum(int(out == y) for out, y in zip(outs, ys))\n",
    "        acc = correct_num / num\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = network(sizes = [784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0943"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机参数时的准确度\n",
    "net.acc(xs=xs_test, ys=ys_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.weights = good_weights\n",
    "net.biases = good_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9379"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 较优参数时的准确度\n",
    "net.acc(xs=xs_test, ys=ys_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找出这组好的参数\n",
    "定义了一个损失函数:\n",
    "$$\n",
    "C(w, b) \\equiv \\frac{1}{n} \\sum_{x} C_{x} = \\frac{1}{2 n} \\sum_{x}\\|y(x)-a_{w,b}(x)\\|^{2}\n",
    "$$\n",
    "我们的目的是找到这些好的参数, 满足:\n",
    "\n",
    "$$\n",
    "w^{*}, b^{*}=\\arg \\min _{w, b} C(w,b)\n",
    "$$\n",
    "\n",
    "<img src='https://cdn.jsdelivr.net/gh/HuangJiaLian/DataBase0@master/uPic/2021_11_17_15_grediant.png' width = '50%'/>\n",
    "\n",
    "寻找的这些参数的方法是梯度下降, $v$是由所有的权重和偏置构成的一个高维的向量， 其改变的反向就是损失函数梯度下降的方向。\n",
    "\n",
    "$$\n",
    "v \\rightarrow v^{\\prime}=v-\\eta \\nabla C\n",
    "$$\n",
    "\n",
    "具体到其中的某一个分量的更新方法是,\n",
    "\n",
    "$$\n",
    "w_{k} \\rightarrow w_{k}^{\\prime}=w_{k}-\\eta \\frac{\\partial C}{\\partial w_{k}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_{l} \\rightarrow b_{l}^{\\prime}=b_{l}-\\eta \\frac{\\partial C}{\\partial b_{l}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 随机初始化神经网络的权重和偏置之后， 相当于小球在损失函数平面上的任意位置， 假设就是上图中的初始位置A。\n",
    "- 我们加载一组比较好的权重和偏置之后， 相当于小球在损失函数平面上较低的位置， 假设就是上图中的最佳位置B。\n",
    "- 机器学习就是从A走到B的这么一个过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(self.sizes)\n",
    "        self.weights = [np.random.normal(size=(self.sizes[i], self.sizes[i-1])) for i in range(1, self.num_layers)]\n",
    "        self.biases = [np.random.normal(size=self.sizes[i]) for i in range(1, self.num_layers)]\n",
    "    \n",
    "    # 前向传播\n",
    "    def out(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            a = self.activation_f(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    # 激活函数\n",
    "    def activation_f(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "    \n",
    "    # 准确度， 其中标签ys是one-hot格式\n",
    "    def acc(self, xs, ys):\n",
    "        num = xs.shape[0]\n",
    "        outs = [np.argmax(self.out(x)) for x in xs]\n",
    "        ys = [np.argmax(y) for y in ys]\n",
    "        correct_num = sum(int(out == y) for out, y in zip(outs, ys))\n",
    "        acc = correct_num / num\n",
    "        return acc\n",
    "    \n",
    "    # 损失函数\n",
    "    def loss(self, xs, ys):\n",
    "        num_samples = len(xs)\n",
    "        loss = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            out = self.out(x)\n",
    "            v = y - out \n",
    "            loss = loss + v.dot(v)\n",
    "        loss = loss / (2*num_samples)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = network(sizes = [784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算随机参数时的损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = net.loss(xs=xs, ys=ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8253013009024597"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算较优参数时的损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.weights = good_weights\n",
    "net.biases = good_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = net.loss(xs=xs, ys=ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043179193159425984"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更新参数\n",
    "$$\n",
    "w_{k} \\rightarrow w_{k}^{\\prime}=w_{k}-\\eta \\frac{\\partial C}{\\partial w_{k}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_{l} \\rightarrow b_{l}^{\\prime}=b_{l}-\\eta \\frac{\\partial C}{\\partial b_{l}}\n",
    "$$\n",
    "\n",
    "[反向传播详细推导](https://github.com/way2ml/ML-Course/blob/main/src/backpropagation.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    \n",
    "    # 神经网络的基本属性\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(self.sizes)\n",
    "        self.weights = [np.random.normal(size=(self.sizes[i], self.sizes[i-1])) for i in range(1, self.num_layers)]\n",
    "        self.biases = [np.random.normal(size=self.sizes[i]) for i in range(1, self.num_layers)]\n",
    "    \n",
    "    # 前向传播计算输出\n",
    "    def out(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            a = self.activation_f(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    # 激活函数\n",
    "    def activation_f(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "    \n",
    "    # 激活函数的倒数 (反向传播的时候会用到)\n",
    "    def activation_f_prime(self, z):\n",
    "        return self.activation_f(z)*(1-self.activation_f(z))\n",
    "    \n",
    "    # 损失函数\n",
    "    def loss(self, xs, ys):\n",
    "        num_samples = len(xs)\n",
    "        loss = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            out = self.out(x)\n",
    "            v = y - out \n",
    "            loss = loss + v.dot(v)\n",
    "        loss = loss / (2*num_samples)\n",
    "        return loss\n",
    "    \n",
    "    # 准确度， 其中标签ys是one-hot格式\n",
    "    def acc(self, xs, ys):\n",
    "        num = xs.shape[0]\n",
    "        outs = [np.argmax(self.out(x)) for x in xs]\n",
    "        ys = [np.argmax(y) for y in ys]\n",
    "        correct_num = sum(int(out == y) for out, y in zip(outs, ys))\n",
    "        acc = correct_num / num\n",
    "        return acc\n",
    "    \n",
    "    # 更新参数\n",
    "    def update(self, lr, xs, ys):\n",
    "        # 目的: 找到要更新的量(要微调的量)\n",
    "        nabla_ws = [np.zeros(w.shape) for w in self.weights]\n",
    "        nabla_bs = [np.zeros(b.shape) for b in self.biases]\n",
    "        partial_zs = [np.zeros(b.shape) for b in self.biases]\n",
    "        \n",
    "        # 循环所有训练数据\n",
    "        for x, y in zip(xs, ys):\n",
    "            num_samples = xs.shape[0]\n",
    "            # 前向传播得到每一层的加权求和值z, 与每一层的输出(激活)值a\n",
    "            zs = []\n",
    "            a = x\n",
    "            a_s = [x]\n",
    "            # 循环所有层\n",
    "            for w, b in zip(self.weights, self.biases):\n",
    "                z = np.dot(w, a) + b\n",
    "                a = self.activation_f(z)\n",
    "                zs.append(z)\n",
    "                a_s.append(a)\n",
    "            \n",
    "            # 循环结束后的a即为网络的输出o\n",
    "            o = a_s[-1]\n",
    "            \n",
    "            # 计算梯度\n",
    "            # 最后一层\n",
    "            partial_z = (o - y)*self.activation_f_prime(zs[-1])\n",
    "            partial_zs[-1] = partial_z\n",
    "            \n",
    "            repetitions = self.sizes[-1]\n",
    "            ma = np.transpose([a_s[-2]] * repetitions)\n",
    "            nabla_ws[-1] +=  (ma* partial_zs[-1]).T\n",
    "            nabla_bs[-1] += partial_zs[-1]\n",
    "            # 反向传播 \n",
    "            # 输入层没有加权求和过激活等运算\n",
    "            for n in range(1, self.num_layers -1): \n",
    "                h,  i,  j = -n-2,  -n-1,  -n\n",
    "                partial_z = self.activation_f_prime(zs[i]) * np.dot(self.weights[j].T, partial_zs[j])\n",
    "                partial_zs[i] = partial_z\n",
    "                repetitions = self.sizes[i]\n",
    "                ma = np.transpose([a_s[h]] * repetitions)\n",
    "                nabla_ws[i] +=  (ma* partial_zs[i]).T\n",
    "                nabla_bs[i] += partial_zs[i]\n",
    "        # 更新参数， 使得网络的性能变得更好\n",
    "        # weight 是一个2D的numpy array, weights 是一个列表\n",
    "        # biase 是一个1D的numpy array， biases是一个列表\n",
    "        self.weights = [weight - (lr/num_samples) * nabla_w for weight, nabla_w in zip(self.weights, nabla_ws)]\n",
    "        self.biases = [biase - (lr/num_samples) * nabla_b  for biase,  nabla_b in zip(self.biases, nabla_bs)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = network(sizes = [784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1466383674132503 0.07044\n",
      "0.9394941594433865 0.07322\n",
      "0.791047275235436 0.075\n",
      "0.6983553968382673 0.0769\n",
      "0.6426249963945441 0.07816\n",
      "0.6076381979479398 0.07932\n",
      "0.5842599635610904 0.0802\n",
      "0.5677777442404874 0.08138\n",
      "0.5556565296874889 0.08238\n",
      "0.5464399277685607 0.08376\n"
     ]
    }
   ],
   "source": [
    "# Training \n",
    "for i in range(10):\n",
    "    net.update( lr=1, xs=xs, ys=ys)\n",
    "    print(net.loss(xs=xs, ys=ys), net.acc(xs=xs, ys=ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    \n",
    "    # 神经网络的基本属性\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(self.sizes)\n",
    "        self.weights = [np.random.normal(size=(self.sizes[i], self.sizes[i-1])) for i in range(1, self.num_layers)]\n",
    "        self.biases = [np.random.normal(size=self.sizes[i]) for i in range(1, self.num_layers)]\n",
    "    # 前向传播计算输出\n",
    "    def out(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            a = self.activation_f(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    # 激活函数\n",
    "    def activation_f(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "    \n",
    "    # 激活函数的倒数 (反向传播的时候会用到)\n",
    "    def activation_f_prime(self, z):\n",
    "        return self.activation_f(z)*(1-self.activation_f(z))\n",
    "    \n",
    "    # 损失函数\n",
    "    def loss(self, xs, ys):\n",
    "        num_samples = len(xs)\n",
    "        loss = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            out = self.out(x)\n",
    "            v = y - out \n",
    "            loss = loss + v.dot(v)\n",
    "        loss = loss / (2*num_samples)\n",
    "        return loss\n",
    "    \n",
    "    # 准确度， 其中标签ys是one-hot格式\n",
    "    def acc(self, xs, ys):\n",
    "        num = xs.shape[0]\n",
    "        outs = [np.argmax(self.out(x)) for x in xs]\n",
    "        ys = [np.argmax(y) for y in ys]\n",
    "        correct_num = sum(int(out == y) for out, y in zip(outs, ys))\n",
    "        acc = correct_num / num\n",
    "        return acc\n",
    "    \n",
    "    # 更新参数\n",
    "    def update(self, lr, xs, ys):\n",
    "        # 目的: 找到要更新的量(要微调的量)\n",
    "        nabla_ws = [np.zeros(w.shape) for w in self.weights]\n",
    "        nabla_bs = [np.zeros(b.shape) for b in self.biases]\n",
    "        partial_zs = [np.zeros(b.shape) for b in self.biases]\n",
    "        \n",
    "        # 循环所有训练数据\n",
    "        for x, y in zip(xs, ys):\n",
    "            num_samples = xs.shape[0]\n",
    "            # 前向传播得到每一层的加权求和值z, 与每一层的输出(激活)值a\n",
    "            zs = []\n",
    "            a = x\n",
    "            a_s = [x]\n",
    "            # 循环所有层\n",
    "            for w, b in zip(self.weights, self.biases):\n",
    "                z = np.dot(w, a) + b\n",
    "                a = self.activation_f(z)\n",
    "                zs.append(z)\n",
    "                a_s.append(a)\n",
    "            \n",
    "            # 循环结束后的a即为网络的输出o\n",
    "            o = a_s[-1]\n",
    "            \n",
    "            # 计算梯度\n",
    "            # 最后一层\n",
    "            partial_z = (o - y)*self.activation_f_prime(zs[-1])\n",
    "            partial_zs[-1] = partial_z\n",
    "            \n",
    "            repetitions = self.sizes[-1]\n",
    "            ma = np.transpose([a_s[-2]] * repetitions)\n",
    "            nabla_ws[-1] +=  (ma* partial_zs[-1]).T\n",
    "            nabla_bs[-1] += partial_zs[-1]\n",
    "            # 反向传播 \n",
    "            # 输入层没有加权求和过激活等运算\n",
    "            for n in range(1, self.num_layers -1): \n",
    "                h,  i,  j = -n-2,  -n-1,  -n\n",
    "                partial_z = self.activation_f_prime(zs[i]) * np.dot(self.weights[j].T, partial_zs[j])\n",
    "                partial_zs[i] = partial_z\n",
    "                repetitions = self.sizes[i]\n",
    "                ma = np.transpose([a_s[h]] * repetitions)\n",
    "                nabla_ws[i] +=  (ma* partial_zs[i]).T\n",
    "                nabla_bs[i] += partial_zs[i]\n",
    "        # 更新参数， 使得网络的性能变得更好\n",
    "        # weight 是一个2D的numpy array, weights 是一个列表\n",
    "        # biase 是一个1D的numpy array， biases是一个列表\n",
    "        self.weights = [weight - (lr/num_samples) * nabla_w for weight, nabla_w in zip(self.weights, nabla_ws)]\n",
    "        self.biases = [biase - (lr/num_samples) * nabla_b  for biase,  nabla_b in zip(self.biases, nabla_bs)] \n",
    "        \n",
    "    def sgd(self, xs, ys, lr, epochs, batch_size):\n",
    "        assert xs.shape[0] == ys.shape[0]\n",
    "        \n",
    "        #  打乱顺序\n",
    "        p = np.random.permutation(xs.shape[0])\n",
    "        xs, ys = xs[p], ys[p]\n",
    "        \n",
    "        # 一大堆训练数据分成很多小份\n",
    "        n = xs.shape[0]\n",
    "        xs_batches = [ xs[k:k+batch_size] for k in range(0, n, batch_size)]\n",
    "        ys_batches = [ ys[k:k+batch_size] for k in range(0, n, batch_size)]\n",
    "        for epoch in range(epochs):\n",
    "            for xs_batch, ys_batch in zip(xs_batches, ys_batches):\n",
    "                # 用一小份数据去更新参数\n",
    "                self.update(lr=lr, xs=xs_batch, ys=ys_batch)\n",
    "            loss = self.loss(xs=xs, ys=ys)\n",
    "            acc = self.acc(xs=xs, ys=ys)\n",
    "            print('epoch: {:<5}\\t loss: {:.4f}\\t acc: {:.4f}'.format(epoch+1, loss, acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = network(sizes = [784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1    \t loss: 0.2645\t acc: 0.5805\n",
      "epoch: 2    \t loss: 0.1438\t acc: 0.8240\n",
      "epoch: 3    \t loss: 0.1118\t acc: 0.8644\n",
      "epoch: 4    \t loss: 0.0968\t acc: 0.8828\n",
      "epoch: 5    \t loss: 0.0874\t acc: 0.8952\n",
      "epoch: 6    \t loss: 0.0808\t acc: 0.9027\n",
      "epoch: 7    \t loss: 0.0759\t acc: 0.9079\n",
      "epoch: 8    \t loss: 0.0721\t acc: 0.9132\n",
      "epoch: 9    \t loss: 0.0689\t acc: 0.9169\n",
      "epoch: 10   \t loss: 0.0660\t acc: 0.9200\n"
     ]
    }
   ],
   "source": [
    "net.sgd(xs=xs, ys=ys, lr=1, epochs=10, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    # 神经网络的基本属性\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(self.sizes)\n",
    "        self.weights = [np.random.normal(size=(self.sizes[i], self.sizes[i-1])) for i in range(1, self.num_layers)]\n",
    "        self.biases = [np.random.normal(size=self.sizes[i]) for i in range(1, self.num_layers)]\n",
    "    \n",
    "    # 前向传播计算输出\n",
    "    def out(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            a = self.activation_f(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    # 激活函数\n",
    "    def activation_f(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "    \n",
    "    # 激活函数的倒数 (反向传播的时候会用到)\n",
    "    def activation_f_prime(self, z):\n",
    "        return self.activation_f(z)*(1-self.activation_f(z))\n",
    "    \n",
    "    # 损失函数\n",
    "    def loss(self, xs, ys):\n",
    "        num_samples = len(xs)\n",
    "        loss = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            out = self.out(x)\n",
    "            v = y - out \n",
    "            loss = loss + v.dot(v)\n",
    "        loss = loss / (2*num_samples)\n",
    "        return loss\n",
    "    \n",
    "    # 准确度， 其中标签ys是one-hot格式\n",
    "    def acc(self, xs, ys):\n",
    "        num = xs.shape[0]\n",
    "        outs = [np.argmax(self.out(x)) for x in xs]\n",
    "        ys = [np.argmax(y) for y in ys]\n",
    "        correct_num = sum(int(out == y) for out, y in zip(outs, ys))\n",
    "        acc = correct_num / num\n",
    "        return acc\n",
    "    \n",
    "    def backprop(self, x, y):\n",
    "        # 目的: 找到要更新的量(要微调的量)\n",
    "        nabla_ws = [np.zeros(w.shape) for w in self.weights]\n",
    "        nabla_bs = [np.zeros(b.shape) for b in self.biases]\n",
    "        \n",
    "        partial_zs = [np.zeros(b.shape) for b in self.biases]\n",
    "        # 前向传播得到每一层的加权求和值z, 与每一层的输出(激活)值a\n",
    "        zs = []\n",
    "        a = x\n",
    "        a_s = [x]\n",
    "        # 循环所有层\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(w, a) + b\n",
    "            a = self.activation_f(z)\n",
    "            zs.append(z)\n",
    "            a_s.append(a)\n",
    "\n",
    "        # 循环结束后的a即为网络的输出o\n",
    "        o = a_s[-1]\n",
    "\n",
    "        # 计算梯度\n",
    "        # 对最后一层\n",
    "        partial_z = (o - y)*self.activation_f_prime(zs[-1])\n",
    "        partial_zs[-1] = partial_z\n",
    "\n",
    "        nabla_ws[-1] =  (a_s[-2].reshape((-1, 1))* partial_zs[-1].reshape((1, -1))).T\n",
    "        nabla_bs[-1] = partial_zs[-1]\n",
    "        # 反向传播 \n",
    "        # 输入层没有加权求和过激活等运算\n",
    "        for n in range(1, self.num_layers -1): \n",
    "            h,  i,  j = -n-2,  -n-1,  -n\n",
    "            partial_z = self.activation_f_prime(zs[i]) * np.dot(self.weights[j].T, partial_zs[j])\n",
    "            partial_zs[i] = partial_z\n",
    "            nabla_ws[i] =  (a_s[h].reshape((-1, 1))* partial_zs[i].reshape((1, -1))).T\n",
    "            nabla_bs[i] = partial_zs[i]       \n",
    "        return nabla_ws, nabla_bs\n",
    "    \n",
    "    # 更新参数\n",
    "    def update(self, lr, xs, ys):\n",
    "        \n",
    "        # 训练样本的数目\n",
    "        num_samples = xs.shape[0]\n",
    "        \n",
    "        # 目的: 找到要更新的量\n",
    "        nabla_ws = [np.zeros(w.shape) for w in self.weights]\n",
    "        nabla_bs = [np.zeros(b.shape) for b in self.biases]\n",
    "        \n",
    "        \n",
    "        # 循环所有训练数据\n",
    "        for x, y in zip(xs, ys):\n",
    "            delta_nabla_ws, delta_nabla_bs = self.backprop(x,y)\n",
    "            nabla_ws = [nw+dnw for nw, dnw in zip(nabla_ws, delta_nabla_ws)]\n",
    "            nabla_bs= [nb+dnb for nb, dnb in zip(nabla_bs, delta_nabla_bs)]\n",
    "        \n",
    "        # 更新参数， 使得网络的性能变得更好\n",
    "        self.weights = [weight - (lr/num_samples) * nabla_w for weight, nabla_w in zip(self.weights, nabla_ws)]\n",
    "        self.biases = [biase - (lr/num_samples) * nabla_b  for biase,  nabla_b in zip(self.biases, nabla_bs)] \n",
    "        \n",
    "    def sgd(self, xs, ys, lr, epochs, batch_size):\n",
    "        assert xs.shape[0] == ys.shape[0]\n",
    "        \n",
    "        #  打乱顺序\n",
    "        p = np.random.permutation(xs.shape[0])\n",
    "        xs, ys = xs[p], ys[p]\n",
    "        \n",
    "        # 一大堆训练数据分成很多小份\n",
    "        n = xs.shape[0]\n",
    "        xs_batches = [ xs[k:k+batch_size] for k in range(0, n, batch_size)]\n",
    "        ys_batches = [ ys[k:k+batch_size] for k in range(0, n, batch_size)]\n",
    "        for epoch in range(epochs):\n",
    "            for xs_batch, ys_batch in zip(xs_batches, ys_batches):\n",
    "                # 用一小份数据去更新参数\n",
    "                self.update(lr=lr, xs=xs_batch, ys=ys_batch)\n",
    "            loss = self.loss(xs=xs, ys=ys)\n",
    "            acc = self.acc(xs=xs, ys=ys)\n",
    "            print('epoch: {:<5}\\t loss: {:.4f}\\t acc: {:.4f}'.format(epoch+1, loss, acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = network(sizes = [784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1    \t loss: 0.1943\t acc: 0.7358\n",
      "epoch: 2    \t loss: 0.1535\t acc: 0.7895\n",
      "epoch: 3    \t loss: 0.1371\t acc: 0.8090\n",
      "epoch: 4    \t loss: 0.1272\t acc: 0.8196\n",
      "epoch: 5    \t loss: 0.1209\t acc: 0.8269\n",
      "epoch: 6    \t loss: 0.1161\t acc: 0.8314\n",
      "epoch: 7    \t loss: 0.1124\t acc: 0.8344\n",
      "epoch: 8    \t loss: 0.1093\t acc: 0.8375\n",
      "epoch: 9    \t loss: 0.1067\t acc: 0.8401\n",
      "epoch: 10   \t loss: 0.1045\t acc: 0.8422\n"
     ]
    }
   ],
   "source": [
    "net.sgd(xs=xs, ys=ys, lr=1, epochs=10, batch_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 接下来"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**理论**:\n",
    "\n",
    "- Hung-yi Lee 机器学习课程 https://www.youtube.com/c/HungyiLeeNTU\n",
    "\n",
    "\n",
    "**工具**:\n",
    "\n",
    "- https://www.tensorflow.org/\n",
    "<img src='https://www.gstatic.com/devrel-devsite/prod/v83c28b42a9d2de845cf6ea5b33e8c3314f0e1ea60229353829f7578993509959/tensorflow/images/lockup.svg' width='40%'/>\n",
    "- 或者 https://pytorch.org/ \n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/9/96/Pytorch_logo.png' width='40%'>\n",
    "\n",
    "\n",
    "**讨论**:\n",
    "\n",
    "- 课程讨论 https://github.com/way2ml/forum/discussions/13\n",
    "<img src='https://raw.githubusercontent.com/way2ml/forum/main/logo/forum_logo.png' width='50%'>\n",
    "- way2ml: https://www.way2ml.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 谢谢大家"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
